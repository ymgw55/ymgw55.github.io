[{"authors":["admin"],"categories":null,"content":"My name is Hiroaki Yamagiwa (山際 宏明). I\u0026rsquo;m a third year P.h.D student at Shimodaira Lab, Department of System Science, Informatics, Kyoto University.\n","date":1579387391,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1579387391,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"My name is Hiroaki Yamagiwa (山際 宏明). I\u0026rsquo;m a third year P.h.D student at Shimodaira Lab, Department of System Science, Informatics, Kyoto University.","tags":null,"title":"Hiroaki Yamagiwa","type":"authors"},{"authors":["Hiroaki Yamagiwa","Ryoma Hashimoto","Kiwamu Arakane","Ken Murakami","Shou Soeda","Momose Oyama","Mariko Okada","Hidetoshi Shimodaira"],"categories":["preprint","2024"],"content":"","date":1717467795,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1717467795,"objectID":"d97f2a314fbc3e39da10260e67fca250","permalink":"/publication/drug_gene_analogy/","publishdate":"2024-06-04T11:23:15+09:00","relpermalink":"/publication/drug_gene_analogy/","section":"publication","summary":"","tags":["Embedding"],"title":"Predicting Drug-Gene Relations via Analogy Tasks with Word Embeddings","type":"publication"},{"authors":["大山 百々勢","山際 宏明","下平 英寿"],"categories":["NLP","NLP2024","2024"],"content":"","date":1710289800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1710289800,"objectID":"5f85a2fd49795f38d19569a3530887cd","permalink":"/talk/nlp2024/","publishdate":"2024-02-07T09:30:00+09:00","relpermalink":"/talk/nlp2024/","section":"talk","summary":"言語処理学会第30回年次大会 (NLP 2024)","tags":["ICA","Embedding"],"title":"依存関係の大きさは意味の関連性を表す","type":"talk"},{"authors":["山際 宏明*","大山 百々勢*","下平 英寿"],"categories":["ICT","ICT18","2024"],"content":"","date":1708491600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1708491600,"objectID":"9c2212d200a06ec568166f107c5d6708","permalink":"/talk/ict18/","publishdate":"2024-02-27T16:58:34+09:00","relpermalink":"/talk/ict18/","section":"talk","summary":"京都大学第18回ICTイノベーション","tags":["ICA","Embedding","Cross-Lingual"],"title":"独立成分分析は埋め込み空間の普遍的な幾何学的形状を明らかにする","type":"talk"},{"authors":["Hiroaki Yamagiwa","Yusuke Takase","Hidetoshi Shimodaira"],"categories":["preprint","2024"],"content":"","date":1705001740,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1705001740,"objectID":"eae541b3186eb0991692598ca7763fea","permalink":"/publication/axis_tour/","publishdate":"2024-01-12T04:35:40+09:00","relpermalink":"/publication/axis_tour/","section":"publication","summary":"Word embedding is one of the most important components in natural language processing, but interpreting high-dimensional embeddings remains a challenging problem. To address this problem, Independent Component Analysis (ICA) is identified as an effective solution. ICA-transformed word embeddings reveal interpretable semantic axes; however, the order of these axes are arbitrary. In this study, we focus on this property and propose a novel method, Axis Tour, which optimizes the order of the axes. Inspired by Word Tour, a one-dimensional word embedding method, we aim to improve the clarity of the word embedding space by maximizing the semantic continuity of the axes. Furthermore, we show through experiments on downstream tasks that Axis Tour constructs better low-dimensional embeddings compared to both PCA and ICA.","tags":["ICA","Embedding"],"title":"Axis Tour: Word Tour Determines the Order of Axes in ICA-transformed Embeddings","type":"publication"},{"authors":["Hiroaki Yamagiwa","Yusuke Takase","Hiroyuki Kambe","Ryosuke Nakamoto"],"categories":["WACV","WACV2024","2024"],"content":"","date":1704212247,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1704212247,"objectID":"a9593a8b9b28bea27d138836026f95ce","permalink":"/publication/scesame/","publishdate":"2023-11-17T01:17:27+09:00","relpermalink":"/publication/scesame/","section":"publication","summary":"This paper proposes a novel zero-shot edge detection with SCESAME, which stands for Spectral Clustering-based Ensemble for Segment Anything Model Estimation, based on the recently proposed Segment Anything Model (SAM). SAM is a foundation model for segmentation tasks, and one of the interesting applications of SAM is Automatic Mask Generation (AMG), which generates zero-shot segmentation masks of an entire image. AMG can be applied to edge detection, but suffers from the problem of overdetecting edges. Edge detection with SCESAME overcomes this problem by three steps: (1) eliminating small generated masks, (2) combining masks by spectral clustering, taking into account mask positions and overlaps, and (3) removing artifacts after edge detection. We performed edge detection experiments on two datasets, BSDS500 and NYUDv2. Although our zero-shot approach is simple, the experimental results on BSDS500 showed almost identical performance to human performance and CNN-based methods from seven years ago. In the NYUDv2 experiments, it performed almost as well as recent CNN-based methods. These results indicate that our method effectively enhances the utility of SAM and can be a new direction in zero-shot edge detection methods.","tags":["SAM","Edge-Detection","Zero-Shot"],"title":"Zero-Shot Edge Detection with SCESAME: Spectral Clustering-based Ensemble for Segment Anything Model Estimation","type":"publication"},{"authors":["Hiroaki Yamagiwa*","Momose Oyama*","Hidetoshi Shimodaira"],"categories":["EMNLP","EMNLP2023","2023"],"content":"","date":1701788401,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1701788401,"objectID":"82b00faf1d04971fba29282bd9942934","permalink":"/publication/universal_ica/","publishdate":"2023-05-23T13:17:14+09:00","relpermalink":"/publication/universal_ica/","section":"publication","summary":"This study utilizes Independent Component Analysis (ICA) to unveil a consistent semantic structure within embeddings of words or images. Our approach extracts independent semantic components from the embeddings of a pre-trained model by leveraging anisotropic information that remains after the whitening process in Principal Component Analysis (PCA). We demonstrate that each embedding can be expressed as a composition of a few intrinsic interpretable axes and that these semantic axes remain consistent across different languages, algorithms, and modalities. The discovery of a universal semantic structure in the geometric patterns of embeddings enhances our understanding of the representations in embeddings.","tags":["ICA","Embedding","Cross-Lingual"],"title":"Discovering Universal Geometry in Embeddings with ICA","type":"publication"},{"authors":["Hiroaki Yamagiwa","Sho Yokoi","Hidetoshi Shimodaira"],"categories":["EMNLP","Findings","EMNLP2023","2023"],"content":"","date":1701788400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1701788400,"objectID":"528096e39d85009403bb7a9600cb2513","permalink":"/publication/wsmd/","publishdate":"2022-11-14T16:10:19+09:00","relpermalink":"/publication/wsmd/","section":"publication","summary":"Measuring the semantic similarity between two sentences is still an important task. The word mover's distance (WMD) computes the similarity via the optimal alignment between the sets of word embeddings. However, WMD does not utilize word order, making it challenging to distinguish sentences with significant overlaps of similar words, even if they are semantically very different. Here, we attempt to improve WMD by incorporating the sentence structure represented by BERT's self-attention matrix (SAM). The proposed method is based on the Fused Gromov-Wasserstein distance, which simultaneously considers the similarity of the word embedding and the SAM for calculating the optimal transport between two sentences. Experiments demonstrate the proposed method enhances WMD and its variants in paraphrase identification with near-equivalent performance in semantic textual similarity. Our code is available at https://github.com/ymgw55/WSMD.","tags":["OT","WMD","Gromov-Wasserstein","Fused Gromov-Wasserstein"],"title":"Improving word mover's distance by leveraging self-attention matrix","type":"publication"},{"authors":["大山 百々勢*","山際 宏明*","下平 英寿"],"categories":["IBIS","IBIS2023","2023"],"content":"","date":1698729000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1698729000,"objectID":"48351056d27d66e57fda23455733f239","permalink":"/talk/ibis2023/","publishdate":"2023-10-07T00:31:12+09:00","relpermalink":"/talk/ibis2023/","section":"talk","summary":"第26回情報論的学習理論ワークショップ (IBIS 2023)","tags":["ICA","Embedding","Cross-Lingual"],"title":"独立成分に基づく埋め込み表現の解釈と普遍的形状の解明","type":"talk"},{"authors":["山際 宏明","石橋 陽一","下平 英寿"],"categories":["YANS","YANS2023","2023"],"content":"","date":1693458000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1693458000,"objectID":"62147e69f63c8bc2365eedd6c97fe5fd","permalink":"/talk/yans2023_yamagiwa/","publishdate":"2023-08-18T04:42:24+09:00","relpermalink":"/talk/yans2023_yamagiwa/","section":"talk","summary":"NLP若手の会 第18回シンポジウム (YANS 2023)","tags":["Contrastive Learning","OT","WMD"],"title":"高性能な文類似度を用いた事前学習モデルの対照学習","type":"talk"},{"authors":["大山 百々勢","山際 宏明","石橋 陽一","下平 英寿"],"categories":["YANS","YANS2023","2023"],"content":"","date":1693449600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1693449600,"objectID":"96a4a4de21ca238ad822934ef75bcbff","permalink":"/talk/yans2023_oyama/","publishdate":"2023-08-18T04:47:10+09:00","relpermalink":"/talk/yans2023_oyama/","section":"talk","summary":"NLP若手の会 第18回シンポジウム (YANS 2023)","tags":["Embedding","LLM","ICA"],"title":"内部表現の幾何に基づく言語モデルの解釈","type":"talk"},{"authors":["山際 宏明","橋本 竜馬","荒金 究","村上 賢","大山 百々勢","下平 英寿","岡田 眞里子"],"categories":["IBIS","IBISML","IBISML50","2023"],"content":"","date":1688102400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1688102400,"objectID":"1158cea8612330edca323f7855c3237c","permalink":"/talk/ibisml50/","publishdate":"2023-06-01T22:59:21+09:00","relpermalink":"/talk/ibisml50/","section":"talk","summary":"第50回IBISML研究会 (NC, BIO, MPS共催)","tags":["Embedding","Bioinformatics","Analogy"],"title":"生物学的パスウェイを用いたBioConceptVecにおけるアナロジータスク","type":"talk"},{"authors":[],"categories":[],"content":"","date":1680972750,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1680972750,"objectID":"909085c43fcec2539687606487a55d82","permalink":"/project/mlpapers/","publishdate":"2023-04-09T01:52:30+09:00","relpermalink":"/project/mlpapers/","section":"project","summary":"","tags":[],"title":"Mlpapers","type":"project"},{"authors":["山際 宏明","横井 祥","下平 英寿"],"categories":["JFSSA","JFSSA2022","2022"],"content":"","date":1662270000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1662270000,"objectID":"91d5f4008904deb1e34ac85b5c1ca6c8","permalink":"/talk/jfssa2022/","publishdate":"2022-11-14T16:43:01+09:00","relpermalink":"/talk/jfssa2022/","section":"talk","summary":"2022年度統計関連学会連合大会","tags":["OT","WMD","Gromov-Wasserstein","Fused Gromov-Wasserstein"],"title":"Self-Attention 行列を用いた最適輸送距離に基づく言い換え識別","type":"talk"},{"authors":["山際 宏明","横井 祥","下平 英寿"],"categories":["IBIS","IBIS2021","2021"],"content":"","date":1636527600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1636527600,"objectID":"399f781d7edabe82179f9c05e8e75004","permalink":"/talk/ibis2021/","publishdate":"2021-11-11T01:41:37+09:00","relpermalink":"/talk/ibis2021/","section":"talk","summary":"第24回情報論的学習理論ワークショップ (IBIS 2021)","tags":["OT","WMD","Gromov-Wasserstein","Fused Gromov-Wasserstein"],"title":"BERTのパラメータを用いた最適輸送距離に基づく言い換え識別の性能評価","type":"talk"},{"authors":["山際 宏明","横井 祥","下平 英寿"],"categories":["YANS","YANS2021","2021"],"content":"","date":1630391400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1630391400,"objectID":"63bc9c5a84fc8518e9beeea59844ea08","permalink":"/talk/yans2021/","publishdate":"2021-08-30T20:51:18+09:00","relpermalink":"/talk/yans2021/","section":"talk","summary":"NLP若手の会 第16回シンポジウム (YANS 2021)","tags":["OT","WMD","Gromov-Wasserstein","Fused Gromov-Wasserstein"],"title":"Self-AttentionとFused Gromov–Wasserstein距離に基づく文類似度計算","type":"talk"},{"authors":["Hiroaki Yamagiwa"],"categories":["settings"],"content":"Hugo 静的サイトジェネレーター\nwowchemy 旧Academic. 早めに wowchemy の仕様に移行する必要あり. (e.g. toml から yaml への移行)\nメニューバーの設定 config/_default/menus.toml で設定. メニューバーに表示させる項目(Home, Posts など) の表示・非表示設定,順番, リンク先などの設定できる.\n自己紹介の設定 content/authors/admin/_index.mdで設定.\nHome ページの設定 content/home/*.md で設定. ここで表示・非表示などの設定ができる. 例えば posts.md であれば, content/post/ と対応していて, このフォルダの中のディレクトリの内容をいくつ表示するか, などを決める.\n[username].github.io/* ページの設定 [username].github.io/post の場合, content/post/_index.md でページのタイトル・サブタイトル等を設定できる.\n新しいページの作成 Document\n publicaton の場合, hugo new content/publication/paper-name で新しく paper-name フォルダが自動作成されて, そのフォルダ内の index.md に書けばよい. その際, home に表示するものは featured: true にする必要がある. talk の場合, hugo new --kind talk talk/my-talk で新しく my-talk フォルダが自動作成されて, そのフォルダ内の index.md に書けばよい. post の場合, hugo new --kind post post/my-article-name で新しくmy-article-nameフォルダが自動作成されて, そのフォルダ内の index.md に書けばよい. slidesの場合, hugo new --kind slide slides/slide-name/index.mdで新しくindex.mdを作成後, 始めにmarkup: blackfridayを挿入する必要がある. (参考: Githubのissue)  Contact の設定 config/_default/params.toml で設定. 電話番号や住所の公開・非公開などが設定できる.\n変更内容の確認 hugo server でサーバーを立ち上げ, localhost:1313 で確認.\n","date":1579387391,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1579387391,"objectID":"89295fdf4b5d5f97ef8a98af1c82ac15","permalink":"/post/how-to-use-academic/","publishdate":"2020-01-19T07:43:11+09:00","relpermalink":"/post/how-to-use-academic/","section":"post","summary":"よく使う操作のメモ","tags":["Hugo"],"title":"wowchemy-hugo-themes の使い方","type":"post"}]